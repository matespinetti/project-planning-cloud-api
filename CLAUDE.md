# ProjectPlanning Cloud Persistence API

## Project Overview

You are building a **FastAPI Cloud Persistence API** that handles all database operations for the ProjectPlanning system. This is a standalone REST API with PostgreSQL that stores project data and is called by the Proxy API.

### Current Scope:

- **POST /api/v1/projects** - Create project with nested etapas and pedidos
- **GET /api/v1/projects/{project_id}** - Retrieve project with all nested data
- **PATCH /api/v1/projects/{project_id}** - Partial update (mainly for Bonita info)
- **DELETE /api/v1/projects/{project_id}** - Delete project (cascade to nested entities)
- **PostgreSQL Database** - Store all project data with relationships
- **UUID Primary Keys** - All IDs are UUIDs generated by database
- **Automatic Timestamps** - created_at and updated_at managed automatically

## Architecture

```
┌─────────────────────┐
│  Proxy API          │
│  (Orchestration)    │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  Cloud API          │  ◄── This API
│  (Persistence)      │
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  PostgreSQL         │
│  Database           │
└─────────────────────┘
```

### Data Flow

**Creating a Project:**
1. Proxy API → Cloud API: POST /api/v1/projects (with nested data, no Bonita info)
2. Cloud API: Generate UUIDs, persist to PostgreSQL
3. Cloud API → Proxy API: Return project with generated IDs
4. (Later) Proxy API → Cloud API: PATCH /api/v1/projects/{id} (add Bonita info)

**Reading a Project:**
1. Proxy API → Cloud API: GET /api/v1/projects/{id}
2. Cloud API: Query PostgreSQL with eager loading
3. Cloud API → Proxy API: Return project with nested data

**Deleting a Project:**
1. Proxy API → Cloud API: DELETE /api/v1/projects/{id}
2. Cloud API: Delete from PostgreSQL (cascades to etapas and pedidos)
3. Cloud API → Proxy API: Return 204 No Content

## Tech Stack

- **Framework:** FastAPI
- **Package Manager:** uv (modern Python package manager)
- **Python Version:** 3.12+
- **Server:** Uvicorn
- **Database:** PostgreSQL 15+
- **ORM:** SQLAlchemy 2.0 (async with asyncpg)
- **Migrations:** Alembic
- **Validation:** Pydantic v2
- **Deployment:** Docker + docker-compose

## Folder Structure

```
project-planning-cloud-api/
├── pyproject.toml              # uv configuration with dependencies
├── uv.lock
├── Dockerfile
├── docker-compose.yml          # PostgreSQL + API
├── alembic.ini                 # Alembic configuration
├── .env.example
├── .env
├── README.md
├── CLAUDE.md                   # This file
│
├── app/
│   ├── __init__.py
│   ├── main.py                 # FastAPI app initialization, CORS, routes
│   ├── config.py               # Pydantic Settings for environment variables
│   │
│   ├── api/
│   │   ├── __init__.py
│   │   └── v1/
│   │       ├── __init__.py
│   │       ├── router.py       # Main API router
│   │       └── endpoints/
│   │           ├── __init__.py
│   │           └── projects.py # CRUD endpoints for projects
│   │
│   ├── models/                 # SQLAlchemy ORM models
│   │   ├── __init__.py
│   │   ├── proyecto.py         # Proyecto table with relationships
│   │   ├── etapa.py            # Etapa table
│   │   └── pedido.py           # Pedido table
│   │
│   ├── schemas/                # Pydantic schemas (request/response)
│   │   ├── __init__.py
│   │   ├── proyecto.py         # ProyectoCreate, ProyectoResponse, ProyectoUpdate
│   │   ├── etapa.py            # EtapaCreate, EtapaResponse
│   │   └── pedido.py           # PedidoCreate, PedidoResponse
│   │
│   ├── crud/                   # Database operations
│   │   ├── __init__.py
│   │   └── proyecto.py         # CRUD operations for projects
│   │
│   └── db/
│       ├── __init__.py
│       ├── base.py             # SQLAlchemy Base class
│       ├── session.py          # Database session management
│       └── init_db.py          # Create tables on startup (optional)
│
├── alembic/
│   ├── env.py                  # Alembic environment configuration
│   └── versions/               # Migration files
│       └── xxxx_initial_schema.py
│
└── tests/
    ├── __init__.py
    ├── conftest.py
    └── test_projects.py
```

## Database Schema

### Tables

#### **proyectos**
Main project table with all project metadata and Bonita tracking.

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| id | UUID | PK | Auto-generated UUID |
| titulo | String(200) | NOT NULL | Project title |
| descripcion | Text | NOT NULL | Project description |
| tipo | String(100) | NOT NULL | Project type |
| pais | String(100) | NOT NULL | Country |
| provincia | String(100) | NOT NULL | Province/State |
| ciudad | String(100) | NOT NULL | City |
| barrio | String(100) | NULLABLE | Neighborhood |
| estado | EstadoProyecto | NOT NULL | Project status (enum) |
| bonita_case_id | String(100) | NULLABLE | Bonita case ID (set later) |
| bonita_process_instance_id | Integer | NULLABLE | Bonita process instance ID |
| created_at | DateTime(TZ) | NOT NULL, DEFAULT now() | Creation timestamp |
| updated_at | DateTime(TZ) | NOT NULL, DEFAULT now(), ON UPDATE now() | Update timestamp |

#### **etapas**
Project stages/phases with date ranges.

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| id | UUID | PK | Auto-generated UUID |
| proyecto_id | UUID | FK(proyectos.id), NOT NULL | Parent project |
| nombre | String(200) | NOT NULL | Stage name |
| descripcion | Text | NOT NULL | Stage description |
| fecha_inicio | Date | NOT NULL | Start date |
| fecha_fin | Date | NOT NULL | End date |

#### **pedidos**
Coverage requests (economic, materials, labor, transport, equipment).

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| id | UUID | PK | Auto-generated UUID |
| etapa_id | UUID | FK(etapas.id), NOT NULL | Parent stage |
| tipo | TipoPedido | NOT NULL | Request type (enum) |
| descripcion | Text | NOT NULL | Request description |
| monto | Float | NULLABLE | Amount (for economico) |
| moneda | String(10) | NULLABLE | Currency code |
| cantidad | Integer | NULLABLE | Quantity (for materiales/mano_obra/etc) |
| unidad | String(50) | NULLABLE | Unit of measurement |

### Enums

**EstadoProyecto:**
- `borrador` - Draft
- `en_planificacion` - In planning
- `buscando_financiamiento` - Seeking funding
- `en_ejecucion` - In execution
- `completo` - Complete

**TipoPedido:**
- `economico` - Economic/financial request
- `materiales` - Materials request
- `mano_obra` - Labor request
- `transporte` - Transport request
- `equipamiento` - Equipment request

### Relationships

- **proyectos → etapas**: One-to-Many, CASCADE DELETE
- **etapas → pedidos**: One-to-Many, CASCADE DELETE
- When a proyecto is deleted, all its etapas are deleted
- When an etapa is deleted, all its pedidos are deleted

### UUID Generation

All IDs are UUIDs (not integers) generated server-side using `uuid.uuid4()`:
```python
id: Mapped[UUID] = mapped_column(PGUUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
```

## API Endpoints

### POST /api/v1/projects

Create a new project with nested etapas and pedidos.

**Request Body:**
```json
{
  "titulo": "Community Center Construction",
  "descripcion": "Build a new community center with multiple facilities",
  "tipo": "Infrastructure",
  "pais": "Argentina",
  "provincia": "Buenos Aires",
  "ciudad": "La Plata",
  "barrio": "Centro",
  "bonita_case_id": null,
  "bonita_process_instance_id": null,
  "estado": "en_planificacion",
  "etapas": [
    {
      "nombre": "Phase 1 - Foundation",
      "descripcion": "Foundation and structural work",
      "fecha_inicio": "2024-01-01",
      "fecha_fin": "2024-03-31",
      "pedidos": [
        {
          "tipo": "economico",
          "descripcion": "Budget for foundation materials",
          "monto": 50000.00,
          "moneda": "ARS",
          "cantidad": null,
          "unidad": null
        },
        {
          "tipo": "materiales",
          "descripcion": "Cement and steel",
          "monto": null,
          "moneda": null,
          "cantidad": 1000,
          "unidad": "kg"
        }
      ]
    }
  ]
}
```

**Response (201 Created):**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "titulo": "Community Center Construction",
  "descripcion": "Build a new community center with multiple facilities",
  "tipo": "Infrastructure",
  "pais": "Argentina",
  "provincia": "Buenos Aires",
  "ciudad": "La Plata",
  "barrio": "Centro",
  "estado": "en_planificacion",
  "bonita_case_id": null,
  "bonita_process_instance_id": null,
  "created_at": "2024-01-15T10:30:00Z",
  "updated_at": "2024-01-15T10:30:00Z",
  "etapas": [
    {
      "id": "660e8400-e29b-41d4-a716-446655440001",
      "proyecto_id": "550e8400-e29b-41d4-a716-446655440000",
      "nombre": "Phase 1 - Foundation",
      "descripcion": "Foundation and structural work",
      "fecha_inicio": "2024-01-01",
      "fecha_fin": "2024-03-31",
      "pedidos": [
        {
          "id": "770e8400-e29b-41d4-a716-446655440002",
          "etapa_id": "660e8400-e29b-41d4-a716-446655440001",
          "tipo": "economico",
          "descripcion": "Budget for foundation materials",
          "monto": 50000.00,
          "moneda": "ARS",
          "cantidad": null,
          "unidad": null
        },
        {
          "id": "880e8400-e29b-41d4-a716-446655440003",
          "etapa_id": "660e8400-e29b-41d4-a716-446655440001",
          "tipo": "materiales",
          "descripcion": "Cement and steel",
          "monto": null,
          "moneda": null,
          "cantidad": 1000,
          "unidad": "kg"
        }
      ]
    }
  ]
}
```

**Key Points:**
- UUIDs are generated automatically by the database
- `created_at` and `updated_at` are set automatically
- `bonita_case_id` and `bonita_process_instance_id` can be null initially
- All nested etapas and pedidos are created in a single transaction
- Returns full nested structure with all generated IDs

### GET /api/v1/projects/{project_id}

Retrieve a project with all nested data.

**Response (200 OK):**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "titulo": "Community Center Construction",
  // ... same structure as POST response
  "etapas": [...]
}
```

**Response (404 Not Found):**
```json
{
  "detail": "Proyecto with id 550e8400-e29b-41d4-a716-446655440000 not found"
}
```

**Key Points:**
- Eager loads all relationships (etapas and pedidos) in a single query
- Returns complete nested structure
- Use `joinedload` for optimal performance

### PATCH /api/v1/projects/{project_id}

Partial update of a project (mainly used to update Bonita info).

**Request Body (Partial):**
```json
{
  "bonita_case_id": "12345",
  "bonita_process_instance_id": 67890
}
```

**Response (200 OK):**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "titulo": "Community Center Construction",
  "bonita_case_id": "12345",
  "bonita_process_instance_id": 67890,
  "updated_at": "2024-01-15T10:35:00Z",
  // ... rest of project data
}
```

**Key Points:**
- Only provided fields are updated
- Uses `exclude_unset=True` to update only provided fields
- `updated_at` is automatically updated
- Returns full project with nested data
- Can also update titulo, descripcion, estado, etc.

### DELETE /api/v1/projects/{project_id}

Delete a project (cascades to etapas and pedidos).

**Response (204 No Content):**
```
(Empty body)
```

**Response (404 Not Found):**
```json
{
  "detail": "Proyecto with id 550e8400-e29b-41d4-a716-446655440000 not found"
}
```

**Key Points:**
- Hard delete (not soft delete)
- Automatically cascades to all etapas and pedidos
- Used by proxy API for rollback when Bonita fails

## SQLAlchemy Models

### Proyecto Model (app/models/proyecto.py)

```python
from datetime import datetime
from typing import List, Optional
from uuid import UUID, uuid4

from sqlalchemy import DateTime, Enum, Integer, String, Text, func
from sqlalchemy.dialects.postgresql import UUID as PGUUID
from sqlalchemy.orm import Mapped, mapped_column, relationship

from app.db.base import Base

import enum as py_enum


class EstadoProyecto(str, py_enum.Enum):
    BORRADOR = "borrador"
    EN_PLANIFICACION = "en_planificacion"
    BUSCANDO_FINANCIAMIENTO = "buscando_financiamiento"
    EN_EJECUCION = "en_ejecucion"
    COMPLETO = "completo"


class Proyecto(Base):
    __tablename__ = "proyectos"

    # Primary Key
    id: Mapped[UUID] = mapped_column(
        PGUUID(as_uuid=True), primary_key=True, default=uuid4
    )

    # Project Info
    titulo: Mapped[str] = mapped_column(String(200), nullable=False)
    descripcion: Mapped[str] = mapped_column(Text, nullable=False)
    tipo: Mapped[str] = mapped_column(String(100), nullable=False)

    # Location
    pais: Mapped[str] = mapped_column(String(100), nullable=False)
    provincia: Mapped[str] = mapped_column(String(100), nullable=False)
    ciudad: Mapped[str] = mapped_column(String(100), nullable=False)
    barrio: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)

    # Status
    estado: Mapped[EstadoProyecto] = mapped_column(
        Enum(EstadoProyecto), nullable=False, default=EstadoProyecto.EN_PLANIFICACION
    )

    # Bonita BPM Integration (can be null initially)
    bonita_case_id: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)
    bonita_process_instance_id: Mapped[Optional[int]] = mapped_column(
        Integer, nullable=True
    )

    # Timestamps (auto-managed)
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now(), nullable=False
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        onupdate=func.now(),
        nullable=False,
    )

    # Relationships
    etapas: Mapped[List["Etapa"]] = relationship(
        back_populates="proyecto", cascade="all, delete-orphan", lazy="joined"
    )
```

### Etapa Model (app/models/etapa.py)

```python
from datetime import date
from typing import List
from uuid import UUID, uuid4

from sqlalchemy import Date, ForeignKey, String, Text
from sqlalchemy.dialects.postgresql import UUID as PGUUID
from sqlalchemy.orm import Mapped, mapped_column, relationship

from app.db.base import Base


class Etapa(Base):
    __tablename__ = "etapas"

    # Primary Key
    id: Mapped[UUID] = mapped_column(
        PGUUID(as_uuid=True), primary_key=True, default=uuid4
    )

    # Foreign Key
    proyecto_id: Mapped[UUID] = mapped_column(
        PGUUID(as_uuid=True), ForeignKey("proyectos.id", ondelete="CASCADE"), nullable=False
    )

    # Etapa Info
    nombre: Mapped[str] = mapped_column(String(200), nullable=False)
    descripcion: Mapped[str] = mapped_column(Text, nullable=False)
    fecha_inicio: Mapped[date] = mapped_column(Date, nullable=False)
    fecha_fin: Mapped[date] = mapped_column(Date, nullable=False)

    # Relationships
    proyecto: Mapped["Proyecto"] = relationship(back_populates="etapas")
    pedidos: Mapped[List["Pedido"]] = relationship(
        back_populates="etapa", cascade="all, delete-orphan", lazy="joined"
    )
```

### Pedido Model (app/models/pedido.py)

```python
from typing import Optional
from uuid import UUID, uuid4

import enum as py_enum
from sqlalchemy import Enum, Float, ForeignKey, Integer, String, Text
from sqlalchemy.dialects.postgresql import UUID as PGUUID
from sqlalchemy.orm import Mapped, mapped_column, relationship

from app.db.base import Base


class TipoPedido(str, py_enum.Enum):
    ECONOMICO = "economico"
    MATERIALES = "materiales"
    MANO_OBRA = "mano_obra"
    TRANSPORTE = "transporte"
    EQUIPAMIENTO = "equipamiento"


class Pedido(Base):
    __tablename__ = "pedidos"

    # Primary Key
    id: Mapped[UUID] = mapped_column(
        PGUUID(as_uuid=True), primary_key=True, default=uuid4
    )

    # Foreign Key
    etapa_id: Mapped[UUID] = mapped_column(
        PGUUID(as_uuid=True), ForeignKey("etapas.id", ondelete="CASCADE"), nullable=False
    )

    # Pedido Info
    tipo: Mapped[TipoPedido] = mapped_column(Enum(TipoPedido), nullable=False)
    descripcion: Mapped[str] = mapped_column(Text, nullable=False)

    # Financial (for economico type)
    monto: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
    moneda: Mapped[Optional[str]] = mapped_column(String(10), nullable=True)

    # Quantity (for materiales, mano_obra, etc.)
    cantidad: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)
    unidad: Mapped[Optional[str]] = mapped_column(String(50), nullable=True)

    # Relationships
    etapa: Mapped["Etapa"] = relationship(back_populates="pedidos")
```

## Pydantic Schemas

### Proyecto Schemas (app/schemas/proyecto.py)

```python
from datetime import datetime
from typing import List, Optional
from uuid import UUID

from pydantic import BaseModel, Field, field_validator

from app.schemas.etapa import EtapaCreate, EtapaResponse


class ProyectoCreate(BaseModel):
    """Schema for creating a proyecto (no IDs, server-generated)."""

    titulo: str = Field(..., min_length=5, max_length=200)
    descripcion: str = Field(..., min_length=20)
    tipo: str = Field(..., min_length=1, max_length=100)
    pais: str = Field(..., max_length=100)
    provincia: str = Field(..., max_length=100)
    ciudad: str = Field(..., max_length=100)
    barrio: Optional[str] = Field(None, max_length=100)
    estado: str = Field(default="en_planificacion")
    bonita_case_id: Optional[str] = Field(None, max_length=100)
    bonita_process_instance_id: Optional[int] = None
    etapas: List[EtapaCreate] = Field(..., min_length=1)

    @field_validator("etapas")
    @classmethod
    def validate_etapas_not_empty(cls, v: List[EtapaCreate]) -> List[EtapaCreate]:
        if not v or len(v) == 0:
            raise ValueError("At least one etapa is required")
        # Validate dates for each etapa
        for etapa in v:
            etapa.validate_dates()
        return v


class ProyectoUpdate(BaseModel):
    """Schema for partial update (PATCH) - all fields optional."""

    titulo: Optional[str] = Field(None, min_length=5, max_length=200)
    descripcion: Optional[str] = Field(None, min_length=20)
    tipo: Optional[str] = Field(None, min_length=1, max_length=100)
    pais: Optional[str] = Field(None, max_length=100)
    provincia: Optional[str] = Field(None, max_length=100)
    ciudad: Optional[str] = Field(None, max_length=100)
    barrio: Optional[str] = Field(None, max_length=100)
    estado: Optional[str] = None
    bonita_case_id: Optional[str] = Field(None, max_length=100)
    bonita_process_instance_id: Optional[int] = None


class ProyectoResponse(BaseModel):
    """Schema for proyecto response with all nested data."""

    model_config = {"from_attributes": True}

    id: UUID
    titulo: str
    descripcion: str
    tipo: str
    pais: str
    provincia: str
    ciudad: str
    barrio: Optional[str] = None
    estado: str
    bonita_case_id: Optional[str] = None
    bonita_process_instance_id: Optional[int] = None
    created_at: datetime
    updated_at: datetime
    etapas: List[EtapaResponse] = []
```

### Etapa Schemas (app/schemas/etapa.py)

```python
from datetime import date
from typing import List
from uuid import UUID

from pydantic import BaseModel, Field, field_validator

from app.schemas.pedido import PedidoCreate, PedidoResponse


class EtapaCreate(BaseModel):
    """Schema for creating an etapa."""

    nombre: str = Field(..., min_length=3, max_length=200)
    descripcion: str = Field(..., min_length=10)
    fecha_inicio: str = Field(...)  # ISO date string from frontend
    fecha_fin: str = Field(...)  # ISO date string from frontend
    pedidos: List[PedidoCreate] = Field(..., min_length=1)

    @field_validator("fecha_inicio", "fecha_fin")
    @classmethod
    def validate_date_format(cls, v: str) -> str:
        try:
            date.fromisoformat(v)
        except ValueError:
            raise ValueError("Date must be in ISO format (YYYY-MM-DD)")
        return v

    @field_validator("pedidos")
    @classmethod
    def validate_pedidos_not_empty(cls, v: List[PedidoCreate]) -> List[PedidoCreate]:
        if not v or len(v) == 0:
            raise ValueError("At least one pedido is required")
        return v

    def validate_dates(self) -> None:
        """Validate fecha_fin >= fecha_inicio."""
        fecha_inicio_date = date.fromisoformat(self.fecha_inicio)
        fecha_fin_date = date.fromisoformat(self.fecha_fin)
        if fecha_fin_date < fecha_inicio_date:
            raise ValueError("fecha_fin must be >= fecha_inicio")


class EtapaResponse(BaseModel):
    """Schema for etapa response."""

    model_config = {"from_attributes": True}

    id: UUID
    proyecto_id: UUID
    nombre: str
    descripcion: str
    fecha_inicio: date
    fecha_fin: date
    pedidos: List[PedidoResponse] = []
```

### Pedido Schemas (app/schemas/pedido.py)

```python
from typing import Optional
from uuid import UUID

from pydantic import BaseModel, Field, field_validator


class PedidoCreate(BaseModel):
    """Schema for creating a pedido."""

    tipo: str = Field(..., min_length=1)
    descripcion: str = Field(..., min_length=5)
    monto: Optional[float] = Field(None, gt=0)
    moneda: Optional[str] = Field(None, max_length=10)
    cantidad: Optional[int] = Field(None, gt=0)
    unidad: Optional[str] = Field(None, max_length=50)

    @field_validator("tipo")
    @classmethod
    def validate_tipo(cls, v: str) -> str:
        allowed = ["economico", "materiales", "mano_obra", "transporte", "equipamiento"]
        if v not in allowed:
            raise ValueError(f"tipo must be one of {allowed}")
        return v


class PedidoResponse(BaseModel):
    """Schema for pedido response."""

    model_config = {"from_attributes": True}

    id: UUID
    etapa_id: UUID
    tipo: str
    descripcion: str
    monto: Optional[float] = None
    moneda: Optional[str] = None
    cantidad: Optional[int] = None
    unidad: Optional[str] = None
```

## CRUD Operations (app/crud/proyecto.py)

```python
from datetime import date
from typing import Optional
from uuid import UUID

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import joinedload

from app.models.etapa import Etapa
from app.models.pedido import Pedido
from app.models.proyecto import Proyecto
from app.schemas.proyecto import ProyectoCreate, ProyectoUpdate


async def create_proyecto(
    db: AsyncSession, proyecto_data: ProyectoCreate
) -> Proyecto:
    """
    Create a proyecto with nested etapas and pedidos in a single transaction.
    """
    # Create Proyecto instance
    db_proyecto = Proyecto(
        titulo=proyecto_data.titulo,
        descripcion=proyecto_data.descripcion,
        tipo=proyecto_data.tipo,
        pais=proyecto_data.pais,
        provincia=proyecto_data.provincia,
        ciudad=proyecto_data.ciudad,
        barrio=proyecto_data.barrio,
        estado=proyecto_data.estado,
        bonita_case_id=proyecto_data.bonita_case_id,
        bonita_process_instance_id=proyecto_data.bonita_process_instance_id,
    )

    # Create Etapas with Pedidos
    for etapa_data in proyecto_data.etapas:
        db_etapa = Etapa(
            nombre=etapa_data.nombre,
            descripcion=etapa_data.descripcion,
            fecha_inicio=date.fromisoformat(etapa_data.fecha_inicio),
            fecha_fin=date.fromisoformat(etapa_data.fecha_fin),
        )

        # Create Pedidos for this Etapa
        for pedido_data in etapa_data.pedidos:
            db_pedido = Pedido(
                tipo=pedido_data.tipo,
                descripcion=pedido_data.descripcion,
                monto=pedido_data.monto,
                moneda=pedido_data.moneda,
                cantidad=pedido_data.cantidad,
                unidad=pedido_data.unidad,
            )
            db_etapa.pedidos.append(db_pedido)

        db_proyecto.etapas.append(db_etapa)

    db.add(db_proyecto)
    await db.commit()
    await db.refresh(db_proyecto)

    return db_proyecto


async def get_proyecto(db: AsyncSession, proyecto_id: UUID) -> Optional[Proyecto]:
    """
    Get a proyecto by ID with all nested data (eager loading).
    """
    stmt = (
        select(Proyecto)
        .where(Proyecto.id == proyecto_id)
        .options(
            joinedload(Proyecto.etapas).joinedload(Etapa.pedidos)
        )
    )
    result = await db.execute(stmt)
    return result.scalar_one_or_none()


async def update_proyecto(
    db: AsyncSession, proyecto_id: UUID, update_data: ProyectoUpdate
) -> Optional[Proyecto]:
    """
    Partial update of a proyecto (PATCH).
    """
    db_proyecto = await get_proyecto(db, proyecto_id)
    if not db_proyecto:
        return None

    # Update only provided fields
    update_dict = update_data.model_dump(exclude_unset=True)
    for key, value in update_dict.items():
        setattr(db_proyecto, key, value)

    await db.commit()
    await db.refresh(db_proyecto)

    return db_proyecto


async def delete_proyecto(db: AsyncSession, proyecto_id: UUID) -> bool:
    """
    Delete a proyecto (cascades to etapas and pedidos).
    """
    db_proyecto = await get_proyecto(db, proyecto_id)
    if not db_proyecto:
        return False

    await db.delete(db_proyecto)
    await db.commit()

    return True
```

## Database Session Management (app/db/session.py)

```python
from typing import AsyncGenerator

from sqlalchemy.ext.asyncio import (
    AsyncSession,
    create_async_engine,
    async_sessionmaker,
)

from app.config import get_settings

settings = get_settings()

# Convert postgresql:// to postgresql+asyncpg://
database_url = settings.DATABASE_URL.replace("postgresql://", "postgresql+asyncpg://")

# Create async engine
engine = create_async_engine(
    database_url,
    pool_pre_ping=True,
    echo=False,  # Set to True for SQL query logging during development
    future=True,
)

# Create AsyncSessionLocal class
AsyncSessionLocal = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
    autocommit=False,
    autoflush=False,
)


async def get_db() -> AsyncGenerator[AsyncSession, None]:
    """
    Dependency that provides an async database session.
    Yields a session and ensures it's closed after use.
    """
    async with AsyncSessionLocal() as session:
        yield session
```

## Base Class (app/db/base.py)

```python
from sqlalchemy.orm import DeclarativeBase


class Base(DeclarativeBase):
    """Base class for all SQLAlchemy models."""
    pass
```

## Configuration (app/config.py)

```python
from functools import lru_cache
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    """Application settings loaded from environment variables."""

    model_config = SettingsConfigDict(env_file=".env", case_sensitive=False)

    # Database
    DATABASE_URL: str

    # API Settings
    API_V1_PREFIX: str = "/api/v1"
    PROJECT_NAME: str = "ProjectPlanning Cloud Persistence API"

    # CORS
    ALLOWED_ORIGINS: str = "http://localhost:3000,http://localhost:8000"

    @property
    def allowed_origins_list(self) -> list[str]:
        """Parse comma-separated origins into a list."""
        return [origin.strip() for origin in self.ALLOWED_ORIGINS.split(",")]


@lru_cache
def get_settings() -> Settings:
    """Create and cache a singleton Settings instance."""
    return Settings()
```

## Alembic Migrations

### Initial Setup

Create `alembic.ini` in project root (generated by `alembic init alembic`).

### Environment Configuration (alembic/env.py)

```python
import asyncio
from logging.config import fileConfig

from sqlalchemy import pool
from sqlalchemy.engine import Connection
from sqlalchemy.ext.asyncio import async_engine_from_config

from alembic import context

# Import your models' Base
from app.db.base import Base
from app.config import get_settings

# Import all models to ensure they're registered
from app.models.proyecto import Proyecto
from app.models.etapa import Etapa
from app.models.pedido import Pedido

# Get settings
settings = get_settings()

# Alembic Config object
config = context.config

# Override database URL from environment
config.set_main_option("sqlalchemy.url", settings.DATABASE_URL.replace("postgresql://", "postgresql+asyncpg://"))

# Interpret the config file for Python logging
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Set target metadata for autogenerate
target_metadata = Base.metadata


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection: Connection) -> None:
    context.configure(connection=connection, target_metadata=target_metadata)

    with context.begin_transaction():
        context.run_migrations()


async def run_async_migrations() -> None:
    """Run migrations in 'online' mode (async)."""
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode."""
    asyncio.run(run_async_migrations())


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
```

### Migration Commands

```bash
# Create initial migration (auto-generate from models)
uv run alembic revision --autogenerate -m "Initial schema with proyectos, etapas, pedidos"

# Apply migrations (upgrade to latest)
uv run alembic upgrade head

# Rollback one migration
uv run alembic downgrade -1

# Show current migration status
uv run alembic current

# Show migration history
uv run alembic history
```

## FastAPI Endpoints Implementation (app/api/v1/endpoints/projects.py)

```python
import logging
from uuid import UUID

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession

from app import crud
from app.db.session import get_db
from app.schemas.proyecto import ProyectoCreate, ProyectoResponse, ProyectoUpdate

logger = logging.getLogger(__name__)
router = APIRouter()


@router.post(
    "/projects",
    response_model=ProyectoResponse,
    status_code=status.HTTP_201_CREATED,
)
async def create_project(
    proyecto_data: ProyectoCreate,
    db: AsyncSession = Depends(get_db),
) -> ProyectoResponse:
    """
    Create a new proyecto with nested etapas and pedidos.
    """
    try:
        logger.info(f"Creating proyecto: {proyecto_data.titulo}")
        db_proyecto = await crud.proyecto.create_proyecto(db, proyecto_data)
        logger.info(f"Successfully created proyecto with ID: {db_proyecto.id}")
        return ProyectoResponse.model_validate(db_proyecto)

    except ValueError as e:
        logger.error(f"Validation error: {e}")
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail=str(e),
        )
    except Exception as e:
        logger.exception(f"Error creating proyecto: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error creating proyecto: {str(e)}",
        )


@router.get("/projects/{project_id}", response_model=ProyectoResponse)
async def get_project(
    project_id: UUID,
    db: AsyncSession = Depends(get_db),
) -> ProyectoResponse:
    """
    Get a proyecto by ID with all nested data.
    """
    logger.info(f"Fetching proyecto {project_id}")
    db_proyecto = await crud.proyecto.get_proyecto(db, project_id)

    if not db_proyecto:
        logger.warning(f"Proyecto {project_id} not found")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Proyecto with id {project_id} not found",
        )

    return ProyectoResponse.model_validate(db_proyecto)


@router.patch("/projects/{project_id}", response_model=ProyectoResponse)
async def update_project(
    project_id: UUID,
    update_data: ProyectoUpdate,
    db: AsyncSession = Depends(get_db),
) -> ProyectoResponse:
    """
    Partial update of a proyecto (mainly for Bonita info).
    """
    logger.info(f"Updating proyecto {project_id}")
    db_proyecto = await crud.proyecto.update_proyecto(db, project_id, update_data)

    if not db_proyecto:
        logger.warning(f"Proyecto {project_id} not found")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Proyecto with id {project_id} not found",
        )

    logger.info(f"Successfully updated proyecto {project_id}")
    return ProyectoResponse.model_validate(db_proyecto)


@router.delete("/projects/{project_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_project(
    project_id: UUID,
    db: AsyncSession = Depends(get_db),
) -> None:
    """
    Delete a proyecto (cascades to etapas and pedidos).
    Used by proxy API for rollback when Bonita fails.
    """
    logger.info(f"Deleting proyecto {project_id}")
    deleted = await crud.proyecto.delete_proyecto(db, project_id)

    if not deleted:
        logger.warning(f"Proyecto {project_id} not found")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Proyecto with id {project_id} not found",
        )

    logger.info(f"Successfully deleted proyecto {project_id}")
```

## Main Application (app/main.py)

```python
import logging

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from app.api.v1.router import api_router
from app.config import get_settings

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title=settings.PROJECT_NAME,
    version="1.0.0",
    description="Cloud Persistence API for ProjectPlanning - Handles all database operations",
    docs_url="/docs",
    redoc_url=None,
    openapi_url="/openapi.json",
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.allowed_origins_list,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include API router
app.include_router(api_router, prefix=settings.API_V1_PREFIX)


@app.get("/")
async def root():
    """Root endpoint - health check."""
    return {
        "message": "ProjectPlanning Cloud Persistence API is running",
        "version": "1.0.0",
        "docs_url": "/docs",
    }


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy"}
```

## Dependencies (pyproject.toml)

```toml
[project]
name = "project-planning-cloud-api"
version = "1.0.0"
description = "Cloud Persistence API for ProjectPlanning - PostgreSQL backend"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.30.0",
    "sqlalchemy[asyncio]>=2.0.0",
    "asyncpg>=0.29.0",
    "alembic>=1.13.0",
    "pydantic>=2.0.0",
    "pydantic-settings>=2.0.0",
    "python-dotenv>=1.0.0",
]

[tool.uv]
dev-dependencies = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "httpx>=0.27.0",
]
```

## Environment Variables (.env.example)

```env
# Database - PostgreSQL connection string
DATABASE_URL=postgresql://projectplanning:projectplanning123@localhost:5432/projectplanning_cloud

# API Settings
API_V1_PREFIX=/api/v1
PROJECT_NAME=ProjectPlanning Cloud Persistence API

# CORS - comma separated list of origins (include proxy API URL)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000
```

## Docker Setup

### Dockerfile

```dockerfile
# Use Python 3.12 slim image
FROM python:3.12-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install uv
RUN curl -LsSf https://astral.sh/uv/install.sh | sh
ENV PATH="/root/.cargo/bin:$PATH"

# Copy dependency files
COPY pyproject.toml uv.lock ./

# Install dependencies
RUN uv sync --frozen --no-dev

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Run migrations and start server
CMD ["sh", "-c", "uv run alembic upgrade head && uv run uvicorn app.main:app --host 0.0.0.0 --port 8000"]
```

### docker-compose.yml

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: projectplanning_cloud_postgres
    environment:
      POSTGRES_USER: projectplanning
      POSTGRES_PASSWORD: projectplanning123
      POSTGRES_DB: projectplanning_cloud
    ports:
      - "5433:5432"  # Use different port to avoid conflicts
    volumes:
      - postgres_cloud_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U projectplanning"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - projectplanning_network

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: projectplanning_cloud_api
    environment:
      DATABASE_URL: postgresql://projectplanning:projectplanning123@postgres:5432/projectplanning_cloud
      API_V1_PREFIX: /api/v1
      PROJECT_NAME: ProjectPlanning Cloud Persistence API
      ALLOWED_ORIGINS: http://localhost:3000,http://localhost:8000
    ports:
      - "8001:8000"  # Expose on port 8001 (proxy API uses 8000)
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - projectplanning_network
    restart: unless-stopped

volumes:
  postgres_cloud_data:

networks:
  projectplanning_network:
    driver: bridge
```

## Development Setup

### Installation

```bash
# Install dependencies with uv
uv sync

# Copy environment file
cp .env.example .env

# Edit .env with your database credentials
```

### Database Migrations

```bash
# Create initial migration (if not exists)
uv run alembic revision --autogenerate -m "Initial schema"

# Apply migrations
uv run alembic upgrade head

# Check current version
uv run alembic current
```

### Run Development Server

```bash
# Run with auto-reload
uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8001

# Access API docs
open http://localhost:8001/docs
```

### Run with Docker

```bash
# Build and start services
docker-compose up --build

# Run in background
docker-compose up -d

# View logs
docker-compose logs -f api

# Stop services
docker-compose down

# Stop and remove volumes (deletes database data)
docker-compose down -v
```

## Testing

### Manual Testing with Swagger UI

1. Open http://localhost:8001/docs
2. Test POST /api/v1/projects with nested data
3. Copy the returned project ID
4. Test GET /api/v1/projects/{id}
5. Test PATCH /api/v1/projects/{id} with Bonita info
6. Test DELETE /api/v1/projects/{id}

### Test Cases

**Create Project:**
- ✅ Valid nested data → 201 Created with generated UUIDs
- ❌ Missing required fields → 422 Validation Error
- ❌ Invalid date format → 422 Validation Error
- ❌ fecha_fin < fecha_inicio → 422 Validation Error
- ❌ Empty etapas array → 422 Validation Error

**Get Project:**
- ✅ Existing project ID → 200 OK with nested data
- ❌ Non-existent ID → 404 Not Found
- ❌ Invalid UUID format → 422 Validation Error

**Update Project:**
- ✅ Valid partial update → 200 OK with updated data
- ✅ Update only bonita_case_id → 200 OK
- ❌ Non-existent ID → 404 Not Found

**Delete Project:**
- ✅ Existing project ID → 204 No Content
- ✅ Verify cascade (etapas and pedidos deleted)
- ❌ Non-existent ID → 404 Not Found

## Common Pitfalls to Avoid

❌ **Don't forget async/await**: All database operations must be async
❌ **Don't forget session management**: Always use `Depends(get_db)` for database session
❌ **Don't forget eager loading**: Use `joinedload()` to avoid N+1 queries
❌ **Don't forget cascade deletes**: Set `cascade="all, delete-orphan"` in relationships
❌ **Don't forget UUIDs**: Use `PGUUID(as_uuid=True)` in SQLAlchemy models
❌ **Don't forget timestamps**: Use `server_default=func.now()` and `onupdate=func.now()`
❌ **Don't forget migrations**: Run `alembic upgrade head` before starting API
❌ **Don't forget CORS**: Add proxy API URL to `ALLOWED_ORIGINS`
❌ **Don't forget validation**: Validate dates, enums, and nested data
❌ **Don't forget error handling**: Catch and log all exceptions properly

## Success Criteria

✅ All 4 endpoints work correctly (POST, GET, PATCH, DELETE)
✅ UUIDs generated automatically by database
✅ Timestamps (created_at, updated_at) auto-managed
✅ Nested creates work (proyecto → etapas → pedidos)
✅ Eager loading returns full nested structure
✅ Cascade deletes work (delete proyecto → deletes etapas → deletes pedidos)
✅ PATCH updates only provided fields
✅ Alembic migrations run successfully
✅ Docker setup works (PostgreSQL + API)
✅ Swagger docs accessible and accurate
✅ Error handling returns proper status codes
✅ Validation prevents invalid data

## Future Enhancements

- **List Endpoint**: `GET /api/v1/projects` with pagination, filtering, sorting
- **Full Update**: `PUT /api/v1/projects/{id}` for complete replacement
- **Individual Entity Endpoints**: CRUD for etapas and pedidos separately
- **Authentication**: API key or JWT token authentication
- **Soft Deletes**: Add `is_deleted` flag instead of hard deletes
- **Audit Trail**: Track who created/updated records (created_by, updated_by)
- **Search**: Full-text search on titulo and descripcion
- **Filtering**: Filter by estado, pais, fecha_creacion, etc.
- **Aggregations**: Count projects by estado, sum pedidos by tipo, etc.
- **Backup/Restore**: Automated database backups
- **Health Checks**: Database connectivity check in /health endpoint
- **Rate Limiting**: Protect API from abuse
- **Caching**: Cache frequently accessed projects

---

## Architecture Decision Records

### ADR-001: Why Async SQLAlchemy?

**Context:** Need to choose between sync and async SQLAlchemy.

**Decision:** Use async SQLAlchemy with asyncpg driver.

**Rationale:**
- Better performance for I/O-bound operations
- Non-blocking database queries
- Scales better with concurrent requests
- Native FastAPI async support
- Modern best practice for new projects

**Consequences:**
- ✅ Better performance and scalability
- ✅ Non-blocking database operations
- ⚠️ Slightly more complex (async/await everywhere)
- ⚠️ Must use asyncpg driver (not psycopg2)

### ADR-002: Why UUID Primary Keys?

**Context:** Need to choose between integer IDs and UUIDs.

**Decision:** Use UUIDs for all primary keys.

**Rationale:**
- Globally unique across services
- No sequential ID exposure
- Better for distributed systems
- Can generate client-side if needed
- No collision risk

**Consequences:**
- ✅ Globally unique identifiers
- ✅ Better security (no sequential IDs)
- ✅ Works well in microservices
- ⚠️ Slightly larger storage (16 bytes vs 4 bytes)
- ⚠️ Indexes slightly less efficient

### ADR-003: Why Hard Deletes Instead of Soft Deletes?

**Context:** Need to decide between hard deletes (remove from database) vs soft deletes (set is_deleted flag).

**Decision:** Use hard deletes for now (simple college project).

**Rationale:**
- Simpler implementation
- No extra filtering needed (`WHERE is_deleted = false`)
- Less storage needed
- Cleaner database
- Good enough for college project
- Can add soft deletes later if needed

**Consequences:**
- ✅ Simpler code and queries
- ✅ Cleaner database
- ⚠️ Can't recover deleted data
- ⚠️ No audit trail for deletions
- 💡 Can add soft deletes in future if needed

---

**End of Documentation**
